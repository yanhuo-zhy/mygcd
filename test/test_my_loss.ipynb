{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_proj, student_out = student(images)\n",
    "# student_proj.shape [Batch_size, feature_size]\n",
    "# student_out.shape [Batch_size, class_num]\n",
    "# f_i表示student_proj[i]，p_i表示student_out[i]，p_i^k表示student_out[i][k]，代表第i个对象属于第k个类别的预测值\n",
    "# \\overline{f}_{k}=\\sum_{i} \\frac{p_{i}^{k}}{\\sum_{k}p_{i}}\\cdot f_{i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Student Outputs:\n",
      "[[0.1 0.3 0.6]\n",
      " [0.5 0.2 0.3]\n",
      " [0.2 0.4 0.4]\n",
      " [0.2 0.4 0.4]]\n",
      "\n",
      "Weighted Features for each class:\n",
      "[[0.47 0.44]\n",
      " [0.56 0.87]\n",
      " [0.67 1.09]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设有以下的小批量数据\n",
    "# student_proj: 3个对象，每个对象的特征大小为2\n",
    "student_proj = np.array([[0.2, 0.7],\n",
    "                         [0.5, 0.1],\n",
    "                         [0.9, 0.8],\n",
    "                         [0.1, 0.8]])\n",
    "\n",
    "# student_out: 3个对象，每个对象有3个类别的预测值\n",
    "student_out = np.array([[0.1, 0.3, 0.6],\n",
    "                        [0.5, 0.2, 0.3],\n",
    "                        [0.2, 0.4, 0.4],\n",
    "                        [0.2, 0.4, 0.4]])\n",
    "\n",
    "# 计算归一化的预测权重\n",
    "normalized_student_out = student_out / student_out.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 计算加权的特征值\n",
    "weighted_features = normalized_student_out.T @ student_proj\n",
    "\n",
    "print(\"Normalized Student Outputs:\")\n",
    "print(normalized_student_out)\n",
    "print(\"\\nWeighted Features for each class:\")\n",
    "print(weighted_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student_proj, student_out = student(images)\n",
    "# student_proj.shape [Batch_size, feature_size]\n",
    "# student_out.shape [Batch_size, class_num]\n",
    "# 对于student_out，我希望得到每一行最小的k个值的对应的类别（索引）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the smallest k values for each row:\n",
      "[[0 1]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 示例数据\n",
    "# student_out = np.array([[0.1, 0.3, 0.6, 0.8, 0.05],\n",
    "#                         [0.5, 0.2, 0.3, 0.7, 0.1],\n",
    "#                         [0.2, 0.4, 0.4, 0.1, 0.6]])\n",
    "\n",
    "k = 2  # 作为示例，选择最小的2个值\n",
    "\n",
    "# 使用 argsort 获取索引，并选择前 k 个最小值的索引\n",
    "smallest_k_indices = np.argsort(student_out)[:, :k]\n",
    "\n",
    "print(\"Indices of the smallest k values for each row:\")\n",
    "print(smallest_k_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.42658599  2.66752621 11.47840543  8.37128286]\n"
     ]
    }
   ],
   "source": [
    "# student_proj.shape [Batch_size, feature_size], weighted_features.shape [class_num, feature_size], smallest_k_indices[Batch_size, k]\n",
    "# 基于这些变量实现 \\sum_{k\\in U}\\frac{1}{||f_{i}-\\overline{f}_{k}||_{2}^{2}}\n",
    "# 其中f_{i}=student_proj[i], \\overline{f}_{k}=weighted_features[k], U=smallest_k_indices[i]\n",
    "results = []\n",
    "\n",
    "for i, f_i in enumerate(student_proj):\n",
    "    U = smallest_k_indices[i]\n",
    "    distances = [np.linalg.norm(f_i - weighted_features[k])**2 for k in U]\n",
    "    result_for_i = np.sum([1/d for d in distances if d > 1e-8])  # 避免除以0\n",
    "    results.append(result_for_i)\n",
    "\n",
    "results = np.array(results)  # Shape: [Batch_size]\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.42658599  2.66752621 11.47840543  8.37128286]\n"
     ]
    }
   ],
   "source": [
    "# 包装一下\n",
    "import numpy as np\n",
    "\n",
    "def compute_results(student_proj, student_out, k):\n",
    "    # 计算归一化的预测权重\n",
    "    normalized_student_out = student_out / student_out.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # 计算加权的特征值\n",
    "    weighted_features = normalized_student_out.T @ student_proj\n",
    "\n",
    "    # 使用 argsort 获取索引，并选择前 k 个最小值的索引\n",
    "    smallest_k_indices = np.argsort(student_out)[:, :k]\n",
    "\n",
    "    results = []\n",
    "    for i, f_i in enumerate(student_proj):\n",
    "        U = smallest_k_indices[i]\n",
    "        distances = [np.linalg.norm(f_i - weighted_features[k])**2 for k in U]\n",
    "        result_for_i = np.sum([1/d for d in distances if d > 1e-8])  # 避免除以0\n",
    "        results.append(result_for_i)\n",
    "\n",
    "    return np.array(results)  # Shape: [Batch_size]\n",
    "\n",
    "# student_proj: 3个对象，每个对象的特征大小为2\n",
    "student_proj = np.array([[0.2, 0.7],\n",
    "                         [0.5, 0.1],\n",
    "                         [0.9, 0.8],\n",
    "                         [0.1, 0.8]])\n",
    "\n",
    "# student_out: 3个对象，每个对象有3个类别的预测值\n",
    "student_out = np.array([[0.1, 0.3, 0.6],\n",
    "                        [0.5, 0.2, 0.3],\n",
    "                        [0.2, 0.4, 0.4],\n",
    "                        [0.2, 0.4, 0.4]])\n",
    "\n",
    "k = 2\n",
    "results = compute_results(student_proj, student_out, k)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gcd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.4266,  2.6675, 11.4784,  8.3713])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_results(student_proj, student_out, k):\n",
    "    # 计算归一化的预测权重\n",
    "    normalized_student_out = student_out / student_out.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # 计算加权的特征值\n",
    "    weighted_features = torch.matmul(normalized_student_out.t(), student_proj)\n",
    "\n",
    "    # 使用 argsort 获取索引，并选择前 k 个最小值的索引\n",
    "    smallest_k_indices = student_out.argsort(dim=1)[:, :k]\n",
    "\n",
    "    results = []\n",
    "    for i, f_i in enumerate(student_proj):\n",
    "        U = smallest_k_indices[i]\n",
    "        distances = [torch.norm(f_i - weighted_features[k]).pow(2) for k in U]\n",
    "        result_for_i = torch.sum(torch.tensor([1/d for d in distances if d > 1e-8]))  # 避免除以0\n",
    "        results.append(result_for_i)\n",
    "\n",
    "    return torch.stack(results)  # Shape: [Batch_size]\n",
    "\n",
    "# 使用示例\n",
    "student_proj = torch.tensor([[0.2, 0.7],\n",
    "                         [0.5, 0.1],\n",
    "                         [0.9, 0.8],\n",
    "                         [0.1, 0.8]])\n",
    "student_out = torch.tensor([[0.1, 0.3, 0.6],\n",
    "                        [0.5, 0.2, 0.3],\n",
    "                        [0.2, 0.4, 0.4],\n",
    "                        [0.2, 0.4, 0.4]])\n",
    "\n",
    "k = 2\n",
    "results = compute_results(student_proj, student_out, k)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.4266,  2.6675, 11.4784,  8.3713])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_results(student_proj, student_out, k):\n",
    "    \"\"\"\n",
    "    Compute results based on the student projections and outputs.\n",
    "    \n",
    "    :param student_proj: Tensor of student projections. Shape: [batch_size, feature_size]\n",
    "    :param student_out: Tensor of student outputs. Shape: [batch_size, num_classes]\n",
    "    :param k: Number of smallest values to consider.\n",
    "    \n",
    "    :return: Tensor of results. Shape: [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Normalize student outputs\n",
    "    normalized_student_out = student_out / student_out.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Step 2: Calculate weighted features\n",
    "    weighted_features = torch.matmul(normalized_student_out.t(), student_proj)\n",
    "\n",
    "    # Step 3: Get smallest k indices from student outputs\n",
    "    smallest_k_indices = student_out.argsort(dim=1)[:, :k]\n",
    "\n",
    "    # Step 4: Compute distances\n",
    "    expanded_proj = student_proj.unsqueeze(1).expand(-1, k, -1)\n",
    "    indexed_weighted_features = torch.gather(weighted_features.unsqueeze(0).expand(student_proj.size(0), -1, -1), \n",
    "                                             1, smallest_k_indices.unsqueeze(2).expand(-1, -1, student_proj.size(1)))\n",
    "    distances = torch.norm(expanded_proj - indexed_weighted_features, dim=2).pow(2)\n",
    "\n",
    "    # Step 5: Calculate final results\n",
    "    results = torch.sum(torch.where(distances > 1e-8, 1.0 / distances, torch.zeros_like(distances)), dim=1)\n",
    "\n",
    "    return results\n",
    "\n",
    "# 使用示例\n",
    "student_proj = torch.tensor([[0.2, 0.7],\n",
    "                             [0.5, 0.1],\n",
    "                             [0.9, 0.8],\n",
    "                             [0.1, 0.8]])\n",
    "student_out = torch.tensor([[0.1, 0.3, 0.6],\n",
    "                            [0.5, 0.2, 0.3],\n",
    "                            [0.2, 0.4, 0.4],\n",
    "                            [0.2, 0.4, 0.4]])\n",
    "\n",
    "k = 2\n",
    "results = compute_results(student_proj, student_out, k)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gcd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入SimGCD模型\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/wang_hp/zhy/SimGCD-main\")\n",
    "from model import DINOHead\n",
    "import torch.nn as nn\n",
    "\n",
    "backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "projector = DINOHead(in_dim=768, out_dim=200, nlayers=3)\n",
    "model = nn.Sequential(backbone, projector).to('cuda')\n",
    "checkpoint = torch.load('/wang_hp/zhy/SimGCD-main/dev_outputs/simgcd/log/init_test_(04.09.2023_|_50.012)/checkpoints/model.pt')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gcd/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "len of labeled: 1500\n",
      "len of unlabeled: 4494\n",
      "len of val: 4494\n"
     ]
    }
   ],
   "source": [
    "# 载入验证集\n",
    "from torchvision import transforms\n",
    "from PIL import ImageOps, ImageFilter\n",
    "import random\n",
    "import pandas as pd\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "image_size = 224\n",
    "interpolation = 3\n",
    "crop_pct = 0.875\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(int(image_size / crop_pct), interpolation),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=torch.tensor(mean),\n",
    "        std=torch.tensor(std))\n",
    "])\n",
    "\n",
    "class CustomCub2011(Dataset):\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    url = 'http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root='/wang_hp/zhy/gcd-task/data', train=True, transform=None, target_transform=None, loader=default_loader, download=True):\n",
    "\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.loader = loader\n",
    "        self.train = train\n",
    "\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        self.uq_idxs = np.array(range(len(self)))\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_url(self.url, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1  # Targets start at 1 by default, so shift to 0\n",
    "        img = self.loader(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        # return img, target, self.uq_idxs[idx]\n",
    "        return img, target, idx\n",
    "\n",
    "def subsample_classes(dataset, include_classes=range(160)):\n",
    "\n",
    "    include_classes_cub = np.array(include_classes) + 1     # CUB classes are indexed 1 --> 200 instead of 0 --> 199\n",
    "    cls_idxs = [x for x, (_, r) in enumerate(dataset.data.iterrows()) if int(r['target']) in include_classes_cub]\n",
    "\n",
    "    # TODO: For now have no target transform\n",
    "    target_xform_dict = {}\n",
    "    for i, k in enumerate(include_classes):\n",
    "        target_xform_dict[k] = i\n",
    "\n",
    "    dataset = subsample_dataset(dataset, cls_idxs)\n",
    "\n",
    "    dataset.target_transform = lambda x: target_xform_dict[x]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def subsample_instances(dataset, prop_indices_to_subsample=0.5):\n",
    "\n",
    "    np.random.seed(0)\n",
    "    subsample_indices = np.random.choice(range(len(dataset)), replace=False,\n",
    "                                         size=(int(prop_indices_to_subsample * len(dataset)),))\n",
    "\n",
    "    return subsample_indices\n",
    "\n",
    "def subsample_dataset(dataset, idxs):\n",
    "\n",
    "    mask = np.zeros(len(dataset)).astype('bool')\n",
    "    mask[idxs] = True\n",
    "\n",
    "    dataset.data = dataset.data[mask]\n",
    "    dataset.uq_idxs = dataset.uq_idxs[mask]\n",
    "\n",
    "    return dataset\n",
    "whole_training_set = CustomCub2011(transform=None, train=True)\n",
    "\n",
    "# 有标签训练集\n",
    "# train_dataset_labelled = deepcopy(whole_training_set)\n",
    "train_dataset_labelled = subsample_classes(deepcopy(whole_training_set), include_classes=range(100))\n",
    "subsample_indices = subsample_instances(train_dataset_labelled)\n",
    "train_dataset_labelled = subsample_dataset(train_dataset_labelled, subsample_indices)\n",
    "print(\"len of labeled:\", len(train_dataset_labelled))\n",
    "\n",
    "# 无标签训练集\n",
    "unlabelled_indices = set(whole_training_set.uq_idxs) - set(train_dataset_labelled.uq_idxs)\n",
    "train_dataset_unlabelled = subsample_dataset(deepcopy(whole_training_set), np.array(list(unlabelled_indices)))\n",
    "print(\"len of unlabeled:\", len(train_dataset_unlabelled))\n",
    "\n",
    "# 验证集\n",
    "val_dataset = deepcopy(train_dataset_unlabelled)\n",
    "val_dataset.transform = test_transform\n",
    "print(\"len of val:\", len(val_dataset))\n",
    "test_loader_unlabelled = DataLoader(val_dataset, num_workers=8,batch_size=256, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, class_num, feature_size, max_features_per_class):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.feature_size = feature_size\n",
    "        self.max_features_per_class = max_features_per_class\n",
    "        \n",
    "        # 使用buffer来保存特征和类别计数\n",
    "        self.register_buffer('feature_bank', torch.zeros(class_num, max_features_per_class, feature_size))\n",
    "        self.register_buffer('feature_counts', torch.zeros(class_num, dtype=torch.long))\n",
    "\n",
    "    def reset_feature_bank(self):\n",
    "        \"\"\"重置特征库在每个epoch开始时调用\"\"\"\n",
    "        self.feature_bank.zero_()\n",
    "        self.feature_counts.zero_()\n",
    "\n",
    "    def update_feature_bank(self, proj, label, pseudo_label):\n",
    "        probs = F.softmax(pseudo_label, dim=1)\n",
    "        max_probs, predictions = probs.max(1)\n",
    "        \n",
    "        for feat, prob, pred in zip(proj, max_probs, predictions):\n",
    "            if prob > 0.6:\n",
    "                if self.feature_counts[pred] < self.max_features_per_class:\n",
    "                    self.feature_bank[pred, self.feature_counts[pred]] = feat\n",
    "                    self.feature_counts[pred] += 1\n",
    "                    \n",
    "    # def compute_loss(self, proj, pseudo_label, k):\n",
    "    #     _, class_indices = torch.topk(pseudo_label, k, largest=False, dim=1)\n",
    "    #     batch_size = proj.size(0)\n",
    "    #     losses = torch.zeros(batch_size).to(proj.device)\n",
    "\n",
    "    #     for i in range(batch_size):\n",
    "    #         distances = []\n",
    "    #         for class_idx in class_indices[i]:\n",
    "    #             class_count = self.feature_counts[class_idx].item()\n",
    "    #             if class_count > 0:\n",
    "    #                 class_features = self.feature_bank[class_idx, :class_count]\n",
    "    #                 distance_matrix = torch.sqrt((proj[i] - class_features).pow(2)).sum(dim=1)\n",
    "    #                 distances.append(distance_matrix)\n",
    "\n",
    "    #         if distances:\n",
    "    #             total_distances = torch.cat(distances)\n",
    "    #             loss_for_i = (1.0 / (total_distances + 1e-8)).sum()\n",
    "    #             losses[i] = loss_for_i\n",
    "\n",
    "    #     return losses.mean()\n",
    "    def compute_loss(self, proj, pseudo_label, k):\n",
    "        _, class_indices = torch.topk(pseudo_label, k, largest=False, dim=1)\n",
    "        batch_size = proj.size(0)\n",
    "\n",
    "        # Create a tensor to hold all distances\n",
    "        all_distances = torch.zeros(batch_size, k).to(proj.device)\n",
    "\n",
    "        for idx, class_set in enumerate(class_indices):\n",
    "            class_counts = self.feature_counts[class_set]\n",
    "            valid_mask = class_counts > 0\n",
    "            valid_classes = class_set[valid_mask]\n",
    "            \n",
    "            # Initialize a tensor to hold distances for the current item in the batch across all valid classes\n",
    "            distances_for_idx = torch.zeros(len(valid_classes)).to(proj.device)\n",
    "            \n",
    "            for j, valid_class in enumerate(valid_classes):\n",
    "                # Extract features for the valid class based on class_counts\n",
    "                valid_class_features = self.feature_bank[valid_class, :class_counts[valid_class].long()]\n",
    "                \n",
    "                # Expand dimensions for broadcasting\n",
    "                expanded_proj = proj[idx].unsqueeze(0).expand_as(valid_class_features)\n",
    "\n",
    "                distance = torch.sqrt((expanded_proj - valid_class_features).pow(2).sum(dim=-1))\n",
    "                distances_for_idx[j] = distance.sum()\n",
    "\n",
    "            all_distances[idx, valid_mask] = distances_for_idx\n",
    "\n",
    "        # Calculate loss\n",
    "        losses = (1.0 / (all_distances.sum(dim=-1) + 1e-8)).sum()\n",
    "        \n",
    "        return losses / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyModel(200, 256, 100).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "proj, preds, targets = [], [], []\n",
    "mask = np.array([])\n",
    "for batch_idx, (images, label, _) in enumerate(test_loader_unlabelled):\n",
    "    images = images.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        imageproj, logits = model(images)\n",
    "        preds.append(logits)\n",
    "        targets.append(label)\n",
    "        proj.append(imageproj)\n",
    "        mask = np.append(mask, np.array([True if x.item() in range(100) else False for x in label]))\n",
    "\n",
    "preds = torch.cat(preds,dim=0)\n",
    "targets = torch.cat(targets,dim=0)\n",
    "proj = torch.cat(proj,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  8,  3,  3,  8,  4,  5,  2,  3,  3,  4,  5,  1,  4,  3,  4,  3,\n",
       "         3,  3,  2,  2,  1,  7,  1,  3,  7,  2,  6,  2,  6,  6,  2,  4,  3,  1,\n",
       "         2,  4,  3,  0,  3,  0,  1,  1,  2,  2,  2,  6,  0,  5,  5,  8,  2,  4,\n",
       "         3,  2,  3,  2,  0,  2,  2,  0,  4,  2,  4,  3,  7,  0,  5,  3,  0,  4,\n",
       "         4,  1,  5,  2,  8,  3,  2,  4,  7,  4,  7,  2,  5,  4,  3,  5,  6,  1,\n",
       "         1,  5,  3,  1,  8,  1,  3,  2,  1,  3,  3,  7, 12, 14,  2, 13,  6, 10,\n",
       "        11, 16, 10,  3,  7,  5,  8,  9, 11,  9,  8,  1, 16, 11, 15,  9,  7,  2,\n",
       "         8,  6,  8,  9,  6,  6, 10,  5,  3,  7,  9, 11,  4,  3,  6,  8, 13,  4,\n",
       "         4,  2,  6,  5, 10,  6, 10,  5,  4, 10,  4, 14,  5,  5,  4,  1, 16,  2,\n",
       "         7,  7, 11, 10,  2,  2,  6,  8,  3,  9,  8, 11,  9, 18,  0,  9, 13,  6,\n",
       "         6, 13,  8,  7, 12,  7,  3,  9,  8,  3,  6, 13,  0, 19,  9,  6, 11,  5,\n",
       "         3,  7], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.update_feature_bank(proj, label, preds/0.1)\n",
    "mymodel.feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[145,  58,  78,  ...,   9, 177, 196],\n",
       "        [193,  32, 145,  ...,  92,  77,  65],\n",
       "        [ 49,   3,   9,  ...,  53,   8,  96],\n",
       "        ...,\n",
       "        [ 55,  38,  96,  ...,  20,  90, 116],\n",
       "        [ 91, 117, 110,  ...,  93,  56,   5],\n",
       "        [ 85, 184,  11,  ..., 102,  94,  91]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, class_indices = torch.topk(preds, 10, largest=False, dim=1)\n",
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  0,  2,  6,  2,  4,  3,  3,  9, 11], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, class_set = 0, class_indices[0]\n",
    "class_counts = mymodel.feature_counts[class_set]\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([145,  78,  28,  20,   6,  40,   9, 177, 196], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mask = class_counts > 0\n",
    "valid_classes = class_set[valid_mask]\n",
    "valid_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(145, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j, valid_class = 0, valid_classes[0]\n",
    "valid_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_class_features = mymodel.feature_bank[valid_class, :mymodel.feature_counts[valid_class]]\n",
    "valid_class_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_proj = proj[idx].unsqueeze(0).expand_as(valid_class_features)\n",
    "distance = torch.sqrt((expanded_proj - valid_class_features).pow(2).sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3680, 1.3606], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
